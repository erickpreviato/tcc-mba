# An√°lise de Sentimentos em Avalia√ß√µes de Disciplinas (NLP)

**Monografia MBA em Ci√™ncia de Dados (MBA - ICMC/USP)** - *Um estudo de caso sobre a aplica√ß√£o de modelos Transformers (BERT) para classificar feedback de alunos no ensino superior.*

## Sobre o Projeto
Este projeto foi desenvolvido como Trabalho de Conclus√£o de Curso (TCC) para o MBA em Ci√™ncia de Dados do **ICMC-USP**. O objetivo foi automatizar a an√°lise de avalia√ß√µes de disciplinas, transformando milhares de coment√°rios textuais n√£o estruturados em *insights* acion√°veis para a gest√£o acad√™mica.

O estudo comparou o desempenho de modelos **Multil√≠ngues** versus modelos **Treinados em Portugu√™s (PT-BR)** na tarefa de classifica√ß√£o de sentimentos (Positivo, Negativo e Neutro).

### Principais Objetivos
* Automatizar a leitura de um grande volume de coment√°rios (Dataset com ~16.500 registros de 2017 a 2023).
* Validar a hip√≥tese de que modelos nativos (BERTimbau) superam modelos multil√≠ngues (XLM-RoBERTa) em contextos espec√≠ficos.
* Criar um pipeline de rotulagem de dados assistido por **LLMs** para otimizar o tempo de anota√ß√£o.

---

## Metodologia e Pipeline
O projeto seguiu um fluxo rigoroso de Ci√™ncia de Dados:

1. **Pr√©-processamento:** Limpeza de texto, remo√ß√£o de stopwords, tokeniza√ß√£o e tratamento de dados ausentes.
2. **Rotula√ß√£o H√≠brida (Inova√ß√£o):** Para criar o *Ground Truth*, foi utilizada uma estrat√©gia de pr√©-classifica√ß√£o com **LLM (Gemini)** seguida de valida√ß√£o humana manual em uma amostra representativa.
3. **Modelagem (Fine-Tuning):** Ajuste fino de modelos pr√©-treinados da arquitetura Transformer:
    * **BERTimbau** (Base e Large) - Treinado em PT-BR.
    * **XLM-RoBERTa** (Base e Large) - Multil√≠ngue.

---

## Resultados Alcan√ßados
O modelo **BERTimbau-Large** apresentou o melhor desempenho geral, confirmando que o pr√©-treinamento na l√≠ngua alvo captura melhor as nuances e g√≠rias do ambiente acad√™mico brasileiro.

| Modelo | Acur√°cia | F1-Score | MCC |
| --- | --- | --- | --- |
| **BERTimbau-Large** | **90,67%** | **90,37%** | **0,8450** |
| BERTimbau-Base | 88,00% | 87,52% | 0,8002 |
| XLM-RoBERTa-Base | 83,33% | 76,91% | 0,7333 |
| XLM-RoBERTa-Large | 81,33% | 74,92% | 0,7018 |

Fonte: Tabela de resultados da monografia.
 
**Insight:** A an√°lise da matriz de confus√£o mostrou que a maior dificuldade dos modelos reside na distin√ß√£o entre a classe **Neutra** e as demais, devido √† subjetividade e ironia presentes nos coment√°rios.

---

## Refer√™ncia Bibliogr√°fica
Caso utilize este trabalho ou parte do c√≥digo, por favor cite:

PREVIATO, E. V. **An√°lise de sentimentos em avalia√ß√µes de disciplinas: um estudo de caso no ensino superior**. 2025. 44 p. Monografia (MBA em Ci√™ncias de Dados) - Instituto de Ci√™ncias Matem√°ticas e de Computa√ß√£o, Universidade de S√£o Paulo, S√£o Carlos, 2025.

---

## üë®‚Äçüíª Autor
**Erick Vansim Previato** *Cientista de Dados | Especialista em IA*
[https://www.linkedin.com/in/erickpreviato](https://www.linkedin.com/in/erickpreviato)

---

Este projeto foi orientado pelo Prof. Dr. Wallace Correa de Oliveira Casaca.