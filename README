# ğŸ“ AnÃ¡lise de Sentimentos em AvaliaÃ§Ãµes de Disciplinas (NLP)

> **Monografia MBA em CiÃªncia de Dados (MBA - ICMC/USP)** > *Um estudo de caso sobre a aplicaÃ§Ã£o de modelos Transformers (BERT) para classificar feedback de alunos no ensino superior.*

## ğŸ“„ Sobre o Projeto

Este projeto foi desenvolvido como Trabalho de ConclusÃ£o de Curso (TCC) para o MBA em CiÃªncia de Dados do **ICMC-USP**. O objetivo foi automatizar a anÃ¡lise de avaliaÃ§Ãµes de disciplinas, transformando milhares de comentÃ¡rios textuais nÃ£o estruturados em *insights* acionÃ¡veis para a gestÃ£o acadÃªmica.

O estudo comparou o desempenho de modelos **MultilÃ­ngues** versus modelos **Treinados em PortuguÃªs (PT-BR)** na tarefa de classificaÃ§Ã£o de sentimentos (Positivo, Negativo e Neutro).

### ğŸ¯ Principais Objetivos

* Automatizar a leitura de um grande volume de comentÃ¡rios (Dataset com ~16.500 registros de 2017 a 2023).


* Validar a hipÃ³tese de que modelos nativos (BERTimbau) superam modelos multilÃ­ngues (XLM-RoBERTa) em contextos especÃ­ficos.


* Criar um pipeline de rotulagem de dados assistido por **LLMs** para otimizar o tempo de anotaÃ§Ã£o.



---

## ğŸ› ï¸ Metodologia e Pipeline

O projeto seguiu um fluxo rigoroso de CiÃªncia de Dados:

1. 
**PrÃ©-processamento:** Limpeza de texto, remoÃ§Ã£o de stopwords, tokenizaÃ§Ã£o e tratamento de dados ausentes.


2. 
**RotulaÃ§Ã£o HÃ­brida (InovaÃ§Ã£o):** Para criar o *Ground Truth*, foi utilizada uma estratÃ©gia de prÃ©-classificaÃ§Ã£o com **LLM (Gemini)** seguida de validaÃ§Ã£o humana manual em uma amostra representativa.


3. **Modelagem (Fine-Tuning):** Ajuste fino de modelos prÃ©-treinados da arquitetura Transformer:
* ğŸ¦œ **BERTimbau** (Base e Large) - Treinado em PT-BR.
* ğŸŒ **XLM-RoBERTa** (Base e Large) - MultilÃ­ngue.



---

## ğŸ“Š Resultados AlcanÃ§ados

O modelo **BERTimbau-Large** apresentou o melhor desempenho geral, confirmando que o prÃ©-treinamento na lÃ­ngua alvo captura melhor as nuances e gÃ­rias do ambiente acadÃªmico brasileiro.

| Modelo | AcurÃ¡cia | F1-Score | MCC |
| --- | --- | --- | --- |
| **BERTimbau-Large** | **90,67%** | **90,37%** | **0,8450** |
| BERTimbau-Base | 88,00% | 87,52% | 0,8002 |
| XLM-RoBERTa-Base | 83,33% | 76,91% | 0,7333 |
| XLM-RoBERTa-Large | 81,33% | 74,92% | 0,7018 |

Fonte: Tabela de resultados da monografia.

> 
> **Insight:** A anÃ¡lise da matriz de confusÃ£o mostrou que a maior dificuldade dos modelos reside na distinÃ§Ã£o entre a classe **Neutra** e as demais, devido Ã  subjetividade e ironia presentes nos comentÃ¡rios.
> 
> 



---

## ğŸ“š ReferÃªncia BibliogrÃ¡fica

Caso utilize este trabalho ou parte do cÃ³digo, por favor cite:

> PREVIATO, E. V. **AnÃ¡lise de sentimentos em avaliaÃ§Ãµes de disciplinas: um estudo de caso no ensino superior**. 2025. 44 p. Monografia (MBA em CiÃªncias de Dados) - Instituto de CiÃªncias MatemÃ¡ticas e de ComputaÃ§Ã£o, Universidade de SÃ£o Paulo, SÃ£o Carlos, 2025.
> 
> 



---

## ğŸ‘¨â€ğŸ’» Autor

**Erick Vansim Previato** *Cientista de Dados | Especialista em IA*

<!-- Colocar link -->

[https://www.linkedin.com/in/erickpreviato](https://www.linkedin.com/in/erickpreviato)

---

Este projeto foi orientado pelo Prof. Dr. Wallace Correa de Oliveira Casaca.